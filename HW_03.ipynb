{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Продвинутое машинное обучение: Домашнее задание 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Реализуйте базовый частотный метод по Шерлоку Холмсу:\n",
    " - подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);\n",
    " - возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе вряд ли сработает), зашифруйте их посредством случайной перестановки символов;\n",
    " - расшифруйте их таким частотным методом.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict, OrderedDict\n",
    "import re \n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('WarAndPeace.txt', encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оставляем только буквы русского алфавита и пробелы\n",
    "full_text_clean = re.findall('[а-я ]', full_text.lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text_clean = ''.join(full_text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#удаляем лишние пробелы\n",
    "full_text_clean = re.sub(' +', ' ', full_text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'война и мир самый известный роман льва николаевича толстого как никакое другое произведение писателя'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_text_clean[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**наш \"контрольный\" текст**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Быть энтузиасткой сделалось ее общественным положением, и иногда, когда ей даже того не хотелось, она, чтобы не обмануть ожиданий людей, знавших ее, делалась энтузиасткой. Сдержанная улыбка, игравшая постоянно на лице Анны Павловны, хотя и не шла к ее отжившим чертам, выражала, как у избалованных детей, постоянное сознание своего милого недостатка, от которого она не хочет, не может и не находит нужным исправляться.\n"
     ]
    }
   ],
   "source": [
    "base_text = 'Быть энтузиасткой сделалось ее общественным положением, и иногда, когда ей даже того не хотелось, она, чтобы не обмануть ожиданий людей, знавших ее, делалась энтузиасткой. Сдержанная улыбка, игравшая постоянно на лице Анны Павловны, хотя и не шла к ее отжившим чертам, выражала, как у избалованных детей, постоянное сознание своего милого недостатка, от которого она не хочет, не может и не находит нужным исправляться.'\n",
    "print(base_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "быть энтузиасткой сделалось ее общественным положением и иногда когда ей даже того не хотелось она чтобы не обмануть ожиданий людей знавших ее делалась энтузиасткой сдержанная улыбка игравшая постоянно на лице анны павловны хотя и не шла к ее отжившим чертам выражала как у избалованных детей постоянное сознание своего милого недостатка от которого она не хочет не может и не находит нужным исправляться\n"
     ]
    }
   ],
   "source": [
    "base_text_clean = re.findall('[а-я ]', base_text.lower().replace('  ', ' ').strip())\n",
    "\n",
    "base_text_clean = ''.join(base_text_clean)\n",
    "\n",
    "base_text_clean = re.sub(' +', ' ', base_text_clean)\n",
    "\n",
    "print(base_text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "класс шифрования посредством случайной перестановки символов\n",
    "'''\n",
    "class Permutations():\n",
    "    def __init__(self, text = ''):\n",
    "        self.text = text\n",
    "        #self.mixed_dict = {}\n",
    "        if len(self.text) > 0:\n",
    "            pass\n",
    "    \n",
    "    def fit(self, text):\n",
    "        assert len(text) > 0\n",
    "        \n",
    "        self.text = text\n",
    "        dd = defaultdict()\n",
    "        base_arr = sorted(list(set(self.text)))\n",
    "        perm_arr = np.random.permutation(base_arr)\n",
    "        for letter_1, letter_2 in zip(base_arr, perm_arr):\n",
    "            dd[letter_1] = letter_2\n",
    "        #print(dd)\n",
    "        self.mixed_dict = dict(dd)\n",
    "    \n",
    "    \n",
    "    def fit_transform(self, text):\n",
    "        self.fit(text)\n",
    "        perm_text = ''\n",
    "        for letter in self.text:\n",
    "            #perm_text.append(self.mixed_dict[letter])\n",
    "            perm_text += self.mixed_dict[letter]\n",
    "        return perm_text\n",
    "    \n",
    "    def get_mixed_dict(self):\n",
    "        return self.mixed_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**проверим работу класса**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = Permutations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'пирзмяуом нувтзшяуаеcе'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm.fit_transform('привет меня зовут Cаша'.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**а это наши перестановки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 'у',\n",
       " 'c': 'а',\n",
       " 'а': 'е',\n",
       " 'в': 'з',\n",
       " 'е': 'м',\n",
       " 'з': 'в',\n",
       " 'и': 'р',\n",
       " 'м': 'о',\n",
       " 'н': ' ',\n",
       " 'о': 'т',\n",
       " 'п': 'п',\n",
       " 'р': 'и',\n",
       " 'т': 'я',\n",
       " 'у': 'ш',\n",
       " 'ш': 'c',\n",
       " 'я': 'н'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm.get_mixed_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**сделаем перестановку символов в нашем \"контрольком\" тексте**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'шьоэкытохзрчиобщдкицмачащиэкммкщшемиоумттьскйщащжмтрмскркртщгцчкбщгцчкмдкцчжмкощгщктмкющомащиэкщтчкпощшьктмкщшсчтхоэкщжрцчтрдкаяцмдкзтчулрюкммкцмачачиэкытохзрчиобщдкицм жчттчнкхаьшбчкрг чулчнкйщиощнттщктчкарвмкчттькйчуащутькющонкрктмклачкбкммкщожрулрскпм очскуь чжчачкбчбкхкрзшчащучттьюкцмомдкйщиощнттщмкищзтчтрмкиущмгщксращгщктмцщиочобчкщокбщощ щгщкщтчктмкющпмоктмксщжмокрктмктчющцроктхжтьскрий чуаноэин'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_text_perm = perm.fit_transform(base_text_clean)\n",
    "base_text_perm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**подсчитаем частоты букв**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "функция подсчета частоты букв \n",
    "'''\n",
    "def get_freq_single(txt):\n",
    "    txt_len = len(txt)\n",
    "    cnt = Counter(txt)\n",
    "    out_freq = defaultdict(float)\n",
    "    for i in cnt:\n",
    "        out_freq[i] = cnt[i] / txt_len\n",
    "    return out_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 0.15933646611554253),\n",
       " ('а', 0.07055626912794517),\n",
       " ('б', 0.014529825158290818),\n",
       " ('в', 0.038742038639034505),\n",
       " ('г', 0.01744359353321337),\n",
       " ('д', 0.025574677214705868),\n",
       " ('е', 0.06635807045170433),\n",
       " ('ж', 0.008521250844711909),\n",
       " ('з', 0.014985540404931089),\n",
       " ('и', 0.05593124318182882),\n",
       " ('й', 0.009691752334370137),\n",
       " ('к', 0.030164603722819004),\n",
       " ('л', 0.042570358844543355),\n",
       " ('м', 0.024877058326869563),\n",
       " ('н', 0.0548091224204098),\n",
       " ('о', 0.09564089638564746),\n",
       " ('п', 0.021610578836396666),\n",
       " ('р', 0.03834562880120359),\n",
       " ('с', 0.043898487868142225),\n",
       " ('т', 0.047786113482460424),\n",
       " ('у', 0.02411857336157103),\n",
       " ('ф', 0.0018868484013290655),\n",
       " ('х', 0.007179075803237139),\n",
       " ('ц', 0.003400696994620375),\n",
       " ('ч', 0.011469353929997768),\n",
       " ('ш', 0.007943803443147181),\n",
       " ('щ', 0.002362852340456745),\n",
       " ('ъ', 0.0004416692287643718),\n",
       " ('ы', 0.01597032232489688),\n",
       " ('ь', 0.016383899517909452),\n",
       " ('э', 0.002542329235537674),\n",
       " ('ю', 0.005454536941807348),\n",
       " ('я', 0.0194724627819543)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#частоты для всего текста\n",
    "full_text_freq = get_freq_single(full_text_clean)\n",
    "sorted(full_text_freq.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 0.01485148514851485),\n",
       " ('а', 0.03712871287128713),\n",
       " ('б', 0.022277227722772276),\n",
       " ('в', 0.0024752475247524753),\n",
       " ('г', 0.017326732673267328),\n",
       " ('д', 0.01485148514851485),\n",
       " ('е', 0.0024752475247524753),\n",
       " ('ж', 0.019801980198019802),\n",
       " ('з', 0.012376237623762377),\n",
       " ('и', 0.03712871287128713),\n",
       " ('й', 0.012376237623762377),\n",
       " ('к', 0.15099009900990099),\n",
       " ('л', 0.009900990099009901),\n",
       " ('м', 0.08168316831683169),\n",
       " ('н', 0.017326732673267328),\n",
       " ('о', 0.0594059405940594),\n",
       " ('п', 0.007425742574257425),\n",
       " ('р', 0.04702970297029703),\n",
       " ('с', 0.019801980198019802),\n",
       " ('т', 0.08663366336633663),\n",
       " ('у', 0.024752475247524754),\n",
       " ('х', 0.01485148514851485),\n",
       " ('ц', 0.027227722772277228),\n",
       " ('ч', 0.08415841584158416),\n",
       " ('ш', 0.01485148514851485),\n",
       " ('щ', 0.10148514851485149),\n",
       " ('ы', 0.0049504950495049506),\n",
       " ('ь', 0.022277227722772276),\n",
       " ('э', 0.01485148514851485),\n",
       " ('ю', 0.01485148514851485),\n",
       " ('я', 0.0024752475247524753)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#частоты букв в контрольком тексте\n",
    "base_text_freq = get_freq_single(base_text_perm)\n",
    "sorted(base_text_freq.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "функция сопоставления наиболее \"похожих\" частот\n",
    "'''\n",
    "def get_most_similar(letter, letter_dict, base_dict):\n",
    "    \n",
    "    delta = 1\n",
    "    idx = -1\n",
    "    \n",
    "    letter_freq = letter_dict[letter]\n",
    "    \n",
    "    for i in base_dict:\n",
    "        if abs(base_dict[i] - letter_freq) < delta:\n",
    "            delta = abs(base_dict[i] - letter_freq)\n",
    "            idx = i    \n",
    "    \n",
    "    return idx #, base_dict[idx], letter_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "зпиз юоизчторипоз рдаророрз аа озэаримаоопя чорояаотая т тоогдо погдо аз дояа иого оа зоиарорз ооо хиозп оа озяоозиз оятдоотз рэдаз чоомйтз аа даророрз юоизчторипоз рдазяоооог зрпзпо тгзомйог чориогооо оо ртэа оооп чомромоп зоиг т оа йро п аа оиятмйтя хазиоя мпзояоро поп з тчзоромооопз даиаз чориогоооа рочооота рмоаго ятрого оадориоипо ои поиозого ооо оа зохаи оа яояаи т оа оозодти озяопя трчзомргизрг\n"
     ]
    }
   ],
   "source": [
    "encoded_text = ''\n",
    "for base_text_letter in base_text_perm:\n",
    "    encoded_text += get_most_similar(base_text_letter, base_text_freq, full_text_freq)\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "функция подсчета точности расшифрованного текста\n",
    "'''\n",
    "def calc_text_accuracy(base_text, predicted_text):\n",
    "    cnt = 0\n",
    "    for letter_1, letter_2 in zip(base_text, predicted_text):\n",
    "        if letter_1 == letter_2:\n",
    "            cnt += 1\n",
    "    return cnt / len(base_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.297029702970297"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_text_accuracy(base_text_clean, encoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Точность получилась так себе. Я решил попробовать улучшить этот результат - мне показалось отличной идеей нормализовать полученные частоты к распределению вероятностей**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "softmax\n",
    "'''\n",
    "def get_prob_single(dict_of_freq):\n",
    "    dd = defaultdict()\n",
    "    probs = softmax([i[1] for i in dict_of_freq.items()])\n",
    "    for num, i in enumerate(dict_of_freq.items()):\n",
    "        dd[i[0]] = probs[num]\n",
    "        #print(num)\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text_prob = get_prob_single(full_text_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_text_prob = get_prob_single(base_text_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'ш': 0.03168254901927859,\n",
       "             'ь': 0.03191869115263402,\n",
       "             'о': 0.03312606652012517,\n",
       "             'э': 0.03168254901927859,\n",
       "             'к': 0.036303154526003766,\n",
       "             'ы': 0.031370408216541815,\n",
       "             'т': 0.034040405067828766,\n",
       "             'х': 0.03168254901927859,\n",
       "             'з': 0.03160422384532779,\n",
       "             'р': 0.03271861699617862,\n",
       "             'ч': 0.033956250833689625,\n",
       "             'и': 0.032396268710142354,\n",
       "             'б': 0.03191869115263402,\n",
       "             'щ': 0.034549728380340164,\n",
       "             'д': 0.03168254901927859,\n",
       "             'ц': 0.032077096243472866,\n",
       "             'м': 0.0338723046445226,\n",
       "             'а': 0.032396268710142354,\n",
       "             'е': 0.031292854712908845,\n",
       "             'у': 0.03199779567515125,\n",
       "             'с': 0.03183978219125941,\n",
       "             'й': 0.03160422384532779,\n",
       "             'ж': 0.03183978219125941,\n",
       "             'г': 0.031761068307563735,\n",
       "             'ю': 0.03168254901927859,\n",
       "             'п': 0.03144815392206817,\n",
       "             'я': 0.031292854712908845,\n",
       "             'л': 0.03152609230582449,\n",
       "             ' ': 0.03168254901927859,\n",
       "             'н': 0.031761068307563735,\n",
       "             'в': 0.031292854712908845})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_text_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ааоа е оаао ооа а оо о о оа     ае ооо   аа а о а  о а о о  ао  а ао   а о а  о а     а о о оа     ео аа     аа  аоа  аоо  оа оео а а  оаоа    о о о оа е оаао ооа а оо аа    а аоааа  оаа оа а а оо а       оое     а а оо о а а оа о    ао  а     оаооаоа е ао а оаа а о  а а а оаа о о   аа о о а а оо а     о а   о  оо  а  аоо а    о оо оа   о а о а а         а е о    а а о о      а ооо  аа аа ооаа ооаоаоа\n"
     ]
    }
   ],
   "source": [
    "encoded_text = ''\n",
    "for base_text_letter in base_text_perm:\n",
    "    encoded_text += get_most_similar(base_text_letter, base_text_prob, full_text_prob)\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15099009900990099"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_text_accuracy(base_text_clean, encoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Получилось совсем плохо. Тогда я решил сделать ранжирование букв - ведь по сути частоты могут отличаться, но, например, пробелов будет больше всего, затем по частоте будет буква \"о\"...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "функция ранжирования букв по частоте\n",
    "'''\n",
    "def get_numerate_dict(dict_of_freq):\n",
    "    dd = defaultdict()\n",
    "    ordered_dict = dict(sorted(dict_of_freq.items(), key = lambda kv:kv[1], reverse = True))\n",
    "    for num, i in enumerate(ordered_dict.items()):\n",
    "        dd[i[0]] = num\n",
    "        #print(num)\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'к': 0, 'щ': 1, 'т': 2, 'ч': 3, 'м': 4, 'о': 5, 'р': 6, 'и': 7, 'а': 8, 'ц': 9, 'у': 10, 'ь': 11, 'б': 12, 'с': 13, 'ж': 14, 'г': 15, 'н': 16, 'ш': 17, 'э': 18, 'х': 19, 'д': 20, 'ю': 21, ' ': 22, 'з': 23, 'й': 24, 'л': 25, 'п': 26, 'ы': 27, 'е': 28, 'я': 29, 'в': 30})\n"
     ]
    }
   ],
   "source": [
    "base_text_num = get_numerate_dict(base_text_freq)\n",
    "print(base_text_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {' ': 0, 'о': 1, 'а': 2, 'е': 3, 'и': 4, 'н': 5, 'т': 6, 'с': 7, 'л': 8, 'в': 9, 'р': 10, 'к': 11, 'д': 12, 'м': 13, 'у': 14, 'п': 15, 'я': 16, 'г': 17, 'ь': 18, 'ы': 19, 'з': 20, 'б': 21, 'ч': 22, 'й': 23, 'ж': 24, 'ш': 25, 'х': 26, 'ю': 27, 'ц': 28, 'э': 29, 'щ': 30, 'ф': 31, 'ъ': 32})\n"
     ]
    }
   ],
   "source": [
    "full_text_num = get_numerate_dict(full_text_freq)\n",
    "print(full_text_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perm.get_mixed_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "гкнь юаныйтесндоз свилелось ии огциснриаакм жолоуиатим т таопве допве из веуи нопо аи бонилось оае хногк аи огмеаынь оутвеатз лэвиз йаерштб ии вилелесь юаныйтесндоз свичуеааея ылкгде тпчершея жоснояаао ае лтщи еаак жерлорак боня т аи шле д ии онутрштм хичнем ркчеуеле дед ы тйгелореаакб виниз жоснояааои сойаеати сроипо мтлопо аивосненде он доночопо оае аи бохин аи моуин т аи аебовтн аыуакм тсжчерлянься\n"
     ]
    }
   ],
   "source": [
    "encoded_text = ''\n",
    "for base_text_letter in base_text_perm:\n",
    "    encoded_text += get_most_similar(base_text_letter, base_text_num, full_text_num)\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3886138613861386"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_text_accuracy(base_text_clean, encoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0,388! прошлый 0.297 - результат улучшился! Воодушевленный успехом я решил, что вот оно! Сейчас все получится!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Вряд ли в результате получилась такая уж хорошая расшифровка, разве что если вы брали в качестве тестовых данных целые рассказы. Но и Шерлок Холмс был не так уж прост: после буквы E, которая действительно выделяется частотой, дальше он анализировал уже конкретные слова и пытался угадать, какими они могли бы быть. Я не знаю, как запрограммировать такой интуитивный анализ, так что давайте просто сделаем следующий логический шаг:\n",
    "\n",
    " - подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам;\n",
    " - проведите тестирование аналогично п.1, но при помощи биграмм.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "функция подсчета частоты биграмм \n",
    "'''\n",
    "def get_freq_bigramm(txt):\n",
    "    txt_len = len(txt) - 1\n",
    "    out_freq = defaultdict(float)\n",
    "    for i in range(txt_len):\n",
    "        out_freq[txt[i:i+2]] += 1\n",
    "    for i in out_freq:\n",
    "        out_freq[i] = out_freq[i] / txt_len\n",
    "    return out_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' а', 0.0028841201716738197),\n",
       " (' б', 0.007249317206398751),\n",
       " (' в', 0.014765509168942646),\n",
       " (' г', 0.005042528287163481),\n",
       " (' д', 0.006781115879828326),\n",
       " (' е', 0.0038017947717518532),\n",
       " (' ж', 0.0016574326960593056),\n",
       " (' з', 0.004054623488099883),\n",
       " (' и', 0.01051736246586032),\n",
       " (' й', 2.6531408505657433e-05)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#частоты для всего текста\n",
    "full_text_bi_freq = get_freq_bigramm(full_text_clean)\n",
    "sorted(full_text_bi_freq.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ж', 0.0024813895781637717),\n",
       " (' о', 0.0024813895781637717),\n",
       " (' ч', 0.007444168734491315),\n",
       " (' щ', 0.0024813895781637717),\n",
       " ('ан', 0.0024813895781637717),\n",
       " ('ар', 0.0024813895781637717),\n",
       " ('ач', 0.01240694789081886),\n",
       " ('ащ', 0.01488833746898263),\n",
       " ('аь', 0.0024813895781637717),\n",
       " ('ая', 0.0024813895781637717)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#частоты букв в контрольком тексте\n",
    "base_text_bi_freq = get_freq_bigramm(base_text_perm)\n",
    "sorted(base_text_bi_freq.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "иэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэиэ\n"
     ]
    }
   ],
   "source": [
    "encoded_text = ''\n",
    "for base_text_bigramm in base_text_perm:\n",
    "    encoded_text += get_most_similar(base_text_bigramm, base_text_bi_freq, full_text_bi_freq)\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Получилось очень плохо. Все из-за маленького объема текста - просто очень мало биграмм и их частоты с реальными вообще не совпадают. Я пробовал брать большие тексты - на уровне книги - результат вполне сносный, но в нашем случае такой вариант не подойдет, потому что наша цель расшифровать короткий текст.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Но и это ещё не всё: биграммы скорее всего тоже далеко не всегда работают. Основная часть задания — в том, как можно их улучшить:\n",
    " - предложите метод обучения перестановки символов в этом задании, основанный на MCMC-сэмплировании, но по-прежнему работающий на основе статистики биграмм;\n",
    " - реализуйте и протестируйте его, убедитесь, что результаты улучшились.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть текст - это цепь Маркова, где буквы являются состояниями. Нужно обучить матрицу переходов между буквами на тренировочном тексте. Далее для каждой перестановки, с помощью которой можно осуществить расшифровку, можно найти правдоподобие этой перестановки, перемножив вероятности всех переходов в расшифрованном тексте. Соответственно можно применить MCMC-семплирование для выбора перестановки из распределения, заданного этим правдоподобием."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCMCDecoder:\n",
    "    def __init__(self):\n",
    "        self.alphabet = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя '\n",
    "        self.char_to_idx = {char: idx for idx, char in enumerate(self.alphabet)}\n",
    "        self.transition_matrix = np.zeros((len(self.alphabet), len(self.alphabet)))\n",
    "    \n",
    "    def fit(self, text):\n",
    "        text = ''.join([char for char in text.lower() if char in self.alphabet])\n",
    "        for i in tqdm.tqdm(range(len(text) - 1), position=0, leave=True):\n",
    "            self.transition_matrix[self.char_to_idx[text[i]], self.char_to_idx[text[i+1]]] += 1\n",
    "        self.transition_matrix = np.clip(self.transition_matrix, 1, None)\n",
    "        self.transition_matrix = (np.log(self.transition_matrix).T \n",
    "                                   - np.log(self.transition_matrix.sum(axis=1))).T\n",
    "        \n",
    "    def translate(self, text, permutation):\n",
    "        transtable = str.maketrans(self.alphabet, ''.join(permutation))\n",
    "        return text.translate(transtable)\n",
    "        \n",
    "    def evaluate_log_likelihood(self, text, permutation):\n",
    "        text = self.translate(text, permutation)\n",
    "        log_likelihood = 0\n",
    "        for i in range(len(text) - 1):\n",
    "            log_likelihood += self.transition_matrix[self.char_to_idx[text[i]], self.char_to_idx[text[i+1]]]\n",
    "        return log_likelihood\n",
    "    \n",
    "    def transform(self, text, n_iters=10000):\n",
    "        permutation = np.array(list(self.alphabet))\n",
    "        random.shuffle(permutation)\n",
    "        current_log_likelihood = self.evaluate_log_likelihood(text, permutation)\n",
    "        best_log_likelihood = current_log_likelihood\n",
    "        best_permutation = permutation.copy()\n",
    "        third_part = n_iters // 3\n",
    "        for i in tqdm.tqdm(range(n_iters), position=0, leave=True):\n",
    "            if i % third_part == 0:\n",
    "                random.shuffle(permutation)\n",
    "                current_log_likelihood = self.evaluate_log_likelihood(text, permutation)\n",
    "            swap_idx = random.sample(range(len(self.alphabet)), 2)\n",
    "            permutation[swap_idx[0]], permutation[swap_idx[1]] = \\\n",
    "                permutation[swap_idx[1]], permutation[swap_idx[0]]\n",
    "            new_log_likelihood = self.evaluate_log_likelihood(text, permutation)\n",
    "            if new_log_likelihood >= current_log_likelihood:\n",
    "                current_log_likelihood = new_log_likelihood\n",
    "                if new_log_likelihood > best_log_likelihood:\n",
    "                    best_log_likelihood = new_log_likelihood\n",
    "                    best_permutation = permutation.copy()\n",
    "            else:\n",
    "                if random.random() < np.exp(new_log_likelihood - current_log_likelihood):\n",
    "                    current_log_likelihood = new_log_likelihood\n",
    "                else:\n",
    "                    permutation[swap_idx[0]], permutation[swap_idx[1]] = \\\n",
    "                        permutation[swap_idx[1]], permutation[swap_idx[0]]\n",
    "        return self.translate(text, best_permutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc = MCMCDecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 640750/640750 [00:02<00:00, 242765.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# обучим наш декодер на всем тексте\n",
    "mcmc.fit(full_text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1284.43it/s]\n"
     ]
    }
   ],
   "source": [
    "#и сделаем тестовую расшифровку контрольного текста \n",
    "encoded_text_mcmc = mcmc.transform(base_text_perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'быть чнтужиастрой смелалось ее объественных полодениех и инозма розма ей маде тозо не котелось она фтобы не обхануть одиманий люмей жнавшик ее мелалась чнтужиастрой смегданная улыбра изгавшая постоянно на лице анны павловны котя и не шла р ее отдивших фегтах выгадала рар у ижбалованнык метей постоянное сожнание своезо хилозо немостатра от ротогозо она не кофет не ходет и не накомит нудных испгавляться'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text_mcmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8366336633663366"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_text_accuracy(base_text_clean, encoded_text_mcmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**результат улучшается! Возможно нужно больше итераций**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3000/3000 [00:02<00:00, 1244.55it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6000/6000 [00:04<00:00, 1294.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 9000/9000 [00:07<00:00, 1282.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 12000/12000 [00:09<00:00, 1292.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 15000/15000 [00:11<00:00, 1304.36it/s]\n",
      " 44%|█████████████████████████████████████▎                                              | 4/9 [00:34<00:43,  8.73s/it]\n"
     ]
    }
   ],
   "source": [
    "acc_max = 0\n",
    "i_max = -1\n",
    "best_text = ''\n",
    "for i in tqdm.tqdm(range(3000, 30000, 3000), position=0, leave=True):\n",
    "    encoded_text_mcmc = mcmc.transform(base_text_perm, n_iters=i)\n",
    "    acc = calc_text_accuracy(base_text_clean, encoded_text_mcmc)\n",
    "    if acc > acc_max:\n",
    "        i_max = i\n",
    "        acc_max = acc\n",
    "        best_text = encoded_text_mcmc\n",
    "    if acc_max > 0.9:\n",
    "        break        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'быть энтузиасткой сделалось ее объественным положением и иногда когда ей даже того не хотелось она чтобы не обмануть ожиданий людей знавших ее делалась энтузиасткой сдержанная улыбка игравшая постоянно на лице анны павловны хотя и не шла к ее отжившим чертам выражала как у избалованных детей постоянное сознание своего милого недостатка от которого она не хочет не может и не находит нужным исправляться'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9975247524752475"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отличный результат. При чтении мне пришла идея, что метрику качества можно считать как долю расшифрованных слов, присутствующих в базовом корпусе, на котором мы считали частоты - тогда мы сможем это использовать и при расшифровывании главного сообщения**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "функция подсчета \"действительных\" (валидных) слов \n",
    "'''\n",
    "def calc_valid_word_accuracy(text, full_text):\n",
    "    set_of_words = set(full_text.split(' '))\n",
    "    cnt = 0\n",
    "    words = text.split(' ')\n",
    "    text_len = len(words)\n",
    "    for word in words:\n",
    "        if word in set_of_words:\n",
    "            cnt += 1\n",
    "    return cnt / text_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3000/3000 [00:02<00:00, 1257.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6000/6000 [00:05<00:00, 1193.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 9000/9000 [00:06<00:00, 1300.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 12000/12000 [00:09<00:00, 1287.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 15000/15000 [00:12<00:00, 1214.69it/s]\n",
      " 44%|█████████████████████████████████████▎                                              | 4/9 [00:36<00:45,  9.08s/it]\n"
     ]
    }
   ],
   "source": [
    "acc_max = 0\n",
    "i_max = -1\n",
    "best_text = ''\n",
    "for i in tqdm.tqdm(range(3000, 30000, 3000), position=0, leave=True):\n",
    "    encoded_text_mcmc = mcmc.transform(base_text_perm, n_iters=i)\n",
    "    acc = calc_valid_word_accuracy(encoded_text_mcmc, full_text_clean)\n",
    "    if acc > acc_max:\n",
    "        i_max = i\n",
    "        acc_max = acc\n",
    "        best_text = encoded_text_mcmc\n",
    "    if acc_max > 0.8:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9354838709677419"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'быть щнтузиасткой сделалось ее объественным положением и иногда когда ей даже того не хотелось она чтобы не обмануть ожиданий людей знавших ее делалась щнтузиасткой сдержанная улыбка игравшая постоянно на лице анны павловны хотя и не шла к ее отжившим чертам выражала как у избалованных детей постоянное сознание своего милого недостатка от которого она не хочет не может и не находит нужным исправляться'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text_mcmc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**получилось очень хорошо**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Расшифруйте сообщение:\n",
    "←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹\n",
    "⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷\n",
    "⇊↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹\n",
    "⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝\n",
    "↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**попробуем теперь что получится на \"боевом\" тексте**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "homework_text = '←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Переведём сначала в алфавит, аналогичный тому на котором расшифровывается сообщение**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'↨⇊↞↲↝↘↙⇆⇙⇞↹⇛⇏←⇠↟⇯⇴↾↷↳⇷↤⇒⇈⇸⇰⇌'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homework_alphabet = ''.join(set(homework_text))\n",
    "homework_alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_alphabet_short = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя '[:len(homework_alphabet)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "transtable = str.maketrans(homework_alphabet, rus_alphabet_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'мнцойтбйтохоамйдкпурцчдбсйоцойфкиаойдкпурцчдбсйамънайзйшакёкйнккгжмдовйъкакпбсйцмёъкйфпкиоарачйнъкпммйтнмёкйтбйтнмйнхмцрцойфпртоцчдкйойфкцзиоамйуръноурцчдбсйгрццйщрйфкнцмхдммйиматмпакмйщрхрдомйъзпнрйекавйъкдмидкйвйдоимёкйдмйкгмжрл'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homework_text_rus = homework_text.translate(transtable)\n",
    "homework_text_rus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#message_decoded, _ = mcmc.transform(homework_text_rus, n_iters=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [00:04<00:00, 2140.79it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 11000/11000 [00:05<00:00, 2171.79it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 12000/12000 [00:06<00:00, 1910.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 13000/13000 [00:06<00:00, 1968.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 14000/14000 [00:06<00:00, 2050.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 15000/15000 [00:07<00:00, 2042.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 16000/16000 [00:07<00:00, 2042.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 17000/17000 [00:08<00:00, 1963.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 18000/18000 [00:08<00:00, 2110.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 19000/19000 [00:09<00:00, 1927.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 20000/20000 [00:09<00:00, 2079.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 21000/21000 [00:10<00:00, 2009.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 22000/22000 [00:11<00:00, 1951.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 23000/23000 [00:10<00:00, 2102.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 24000/24000 [00:12<00:00, 1985.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 25000/25000 [00:12<00:00, 2028.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 26000/26000 [00:12<00:00, 2109.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 27000/27000 [00:13<00:00, 2027.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 28000/28000 [00:13<00:00, 2091.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 29000/29000 [00:13<00:00, 2126.94it/s]\n",
      "                                                                                                                       \r"
     ]
    }
   ],
   "source": [
    "acc_max = 0\n",
    "i_max = -1\n",
    "best_text = ''\n",
    "for i in tqdm.tqdm(range(10000, 30000, 1000), position=0, leave=False):\n",
    "    encoded_text_mcmc = mcmc.transform(homework_text_rus, n_iters=i)\n",
    "    acc = calc_valid_word_accuracy(encoded_text_mcmc, full_text_clean)\n",
    "    if acc > acc_max:\n",
    "        i_max = i\n",
    "        acc_max = acc\n",
    "        best_text = encoded_text_mcmc\n",
    "    if acc_max > 0.8:\n",
    "        break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'если вы вимите нордальный или почти нордальный текст у этого сообщения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный балл за послемнее четвертое замание курса хотя конечно я ничего не обещаш'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Текст вполне читаем, это радует. Для улучшения точности попробуем на другом корпусе. Я взял \"Преступление и наказание\" Достоевского.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'преступление и наказание достоевскогороман фмдостоевского преступление и наказание принадлежит к чис'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('Dostoevskiy_Fedor_Prestuplenie_i_nakazanie.txt', encoding=\"windows-1251\")\n",
    "full_text = f.read()\n",
    "f.close()\n",
    "\n",
    "# оставляем только буквы русского алфавита и пробелы\n",
    "full_text_clean = re.findall('[а-я ]', full_text.lower())\n",
    "\n",
    "full_text_clean = ''.join(full_text_clean)\n",
    "\n",
    "#удаляем лишние пробелы\n",
    "full_text_clean = re.sub(' +', ' ', full_text_clean)\n",
    "\n",
    "full_text_clean[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 1114021/1114021 [00:03<00:00, 316938.47it/s]\n"
     ]
    }
   ],
   "source": [
    "mcmc.fit(full_text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [00:05<00:00, 1726.79it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 11000/11000 [00:05<00:00, 1878.93it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 12000/12000 [00:06<00:00, 1886.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 13000/13000 [00:06<00:00, 1906.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 14000/14000 [00:06<00:00, 2088.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 15000/15000 [00:07<00:00, 1953.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 16000/16000 [00:07<00:00, 2108.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 17000/17000 [00:08<00:00, 2079.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 18000/18000 [00:08<00:00, 2041.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 19000/19000 [00:09<00:00, 2070.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 20000/20000 [00:09<00:00, 2048.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 21000/21000 [00:09<00:00, 2138.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 22000/22000 [00:11<00:00, 1964.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 23000/23000 [00:11<00:00, 2016.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 24000/24000 [00:11<00:00, 2081.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 25000/25000 [00:12<00:00, 2042.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 26000/26000 [00:12<00:00, 2132.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 27000/27000 [00:12<00:00, 2118.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 28000/28000 [00:13<00:00, 2061.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 29000/29000 [00:13<00:00, 2132.57it/s]\n",
      "                                                                                                                       \r"
     ]
    }
   ],
   "source": [
    "acc_max = 0\n",
    "i_max = -1\n",
    "best_text = ''\n",
    "for i in tqdm.tqdm(range(10000, 30000, 1000), position=0, leave=False):\n",
    "    encoded_text_mcmc = mcmc.transform(homework_text_rus, n_iters=i)\n",
    "    acc = calc_valid_word_accuracy(encoded_text_mcmc, full_text_clean)\n",
    "    if acc > acc_max:\n",
    "        i_max = i\n",
    "        acc_max = acc\n",
    "        best_text = encoded_text_mcmc\n",
    "    if acc_max > 0.8:\n",
    "        break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'если вы вимите нордальный или почти нордальный текст у этого сообщения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный балл за послемнее четвертое замание курса хотя конечно я ничего не обещаж'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Да, результат улучшился! Ошибок в тексте очень мало и текст можно прочитать без проблем**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
